{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d): Classification  analysis using neural networks\n",
    "\n",
    "With a well-written code it should now be easy to change the\n",
    "activation function for the output layer.\n",
    "\n",
    "Here we will change the cost function for our neural network code\n",
    "developed in parts b) and c) in order to perform a classification analysis. \n",
    "\n",
    "We will here study the Wisconsin Breast Cancer  data set. This is a typical binary classification problem with just one single output, either True or Fale, $0$ or $1$ etc.\n",
    "You find more information about this at the [Scikit-Learn\n",
    "site](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) or at the [University of California\n",
    "at Irvine](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)). \n",
    "\n",
    "To measure the performance of our classification problem we use the\n",
    "so-called *accuracy* score.  The accuracy is as you would expect just\n",
    "the number of correctly guessed targets $t_i$ divided by the total\n",
    "number of targets, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Accuracy} = \\frac{\\sum_{i=1}^n I(t_i = y_i)}{n} ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $I$ is the indicator function, $1$ if $t_i = y_i$ and $0$\n",
    "otherwise if we have a binary classification problem. Here $t_i$\n",
    "represents the target and $y_i$ the outputs of your FFNN code and $n$ is simply the number of targets $t_i$.\n",
    "\n",
    "Discuss your results and give a critical analysis of the various parameters, including hyper-parameters like the learning rates and the regularization parameter $\\lambda$ (as you did in Ridge Regression), various activation functions, number of hidden layers and nodes and activation functions.  \n",
    "\n",
    "As stated in the introduction, it can also be useful to study other\n",
    "datasets. \n",
    "\n",
    "Again, we strongly recommend that you compare your own neural Network\n",
    "code for classification and pertinent results against a similar code using **Scikit-Learn**  or **tensorflow/keras** or **pytorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN:\n",
    "1. last ned breast cancer data set\n",
    "2. bruk ffnn til klassifikasjon (med ... som siste lag)\n",
    "3. Bruk back propogation for å forbedre svaret\n",
    "4. bruke accuracy til å teste resultatene mine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (569,2) (30,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m batched_layers \u001b[38;5;241m=\u001b[39m [(layers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mT, layers[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m])]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m##fn.create_layers(network_input_size, layer_output_sizes)\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_funcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m layer_grads \u001b[38;5;241m=\u001b[39m fn\u001b[38;5;241m.\u001b[39mbackpropagation_batch(X, layers, activation_funcs, target, activation_ders)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(layer_grads)\n",
      "File \u001b[1;32mc:\\Users\\47958\\OneDrive\\Dokumenter\\Master\\FYS-STK\\ML24UiO\\Project2\\FFNN.py:124\u001b[0m, in \u001b[0;36mfeed_forward_batch\u001b[1;34m(inputs, layers, activation_funcs)\u001b[0m\n\u001b[0;32m    122\u001b[0m a \u001b[38;5;241m=\u001b[39m inputs\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (W, b), activation_func \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(layers, activation_funcs):\n\u001b[1;32m--> 124\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    125\u001b[0m     a \u001b[38;5;241m=\u001b[39m activation_func(z)\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (569,2) (30,) "
     ]
    }
   ],
   "source": [
    "## just downloading the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import autograd.numpy as np\n",
    "from autograd import grad, elementwise_grad\n",
    "import FFNN as fn\n",
    "\n",
    "wisconsin = load_breast_cancer()\n",
    "X = wisconsin.data\n",
    "target = wisconsin.target\n",
    "target = target.reshape(target.shape[0], 1)\n",
    "\n",
    "X_train, X_val, t_train, t_val = train_test_split(X, target)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "#print(X[0].size)\n",
    "\n",
    "#\"\"\"\"\n",
    "network_input_size = X[0].size\n",
    "print(X.size)\n",
    "print(network_input_size)\n",
    "layer_output_sizes = [2, 3, 2]\n",
    "activation_funcs = [fn.sigmoid, fn.sigmoid, fn.ReLU]\n",
    "activation_ders = [fn.sigmoid_der, fn.sigmoid_der, fn.ReLU_der]\n",
    "\n",
    "layers = [(np.random.randn(network_input_size,2), np.random.randn(network_input_size))]\n",
    "batched_layers = [(layers[0][0].T, layers[0][1])]\n",
    "##fn.create_layers(network_input_size, layer_output_sizes)\n",
    "\n",
    "predict = fn.feed_forward_batch(X, layers, activation_funcs)\n",
    "\n",
    "layer_grads = fn.backpropagation_batch(X, layers, activation_funcs, target, activation_ders)\n",
    "print(layer_grads)\n",
    "\n",
    "cost_grad = grad(fn.cost, 0)\n",
    "print(cost_grad(layers, X, activation_funcs, target))\n",
    "\n",
    "cost_grad = grad(fn.cost_batch, 0)\n",
    "print(cost_grad(batched_layers, X, activation_funcs, target))\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
