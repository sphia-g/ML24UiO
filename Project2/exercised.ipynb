{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part d): Classification  analysis using neural networks\n",
    "\n",
    "With a well-written code it should now be easy to change the\n",
    "activation function for the output layer.\n",
    "\n",
    "Here we will change the cost function for our neural network code\n",
    "developed in parts b) and c) in order to perform a classification analysis. \n",
    "\n",
    "We will here study the Wisconsin Breast Cancer  data set. This is a typical binary classification problem with just one single output, either True or Fale, $0$ or $1$ etc.\n",
    "You find more information about this at the [Scikit-Learn\n",
    "site](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) or at the [University of California\n",
    "at Irvine](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)). \n",
    "\n",
    "To measure the performance of our classification problem we use the\n",
    "so-called *accuracy* score.  The accuracy is as you would expect just\n",
    "the number of correctly guessed targets $t_i$ divided by the total\n",
    "number of targets, that is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Accuracy} = \\frac{\\sum_{i=1}^n I(t_i = y_i)}{n} ,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $I$ is the indicator function, $1$ if $t_i = y_i$ and $0$\n",
    "otherwise if we have a binary classification problem. Here $t_i$\n",
    "represents the target and $y_i$ the outputs of your FFNN code and $n$ is simply the number of targets $t_i$.\n",
    "\n",
    "Discuss your results and give a critical analysis of the various parameters, including hyper-parameters like the learning rates and the regularization parameter $\\lambda$ (as you did in Ridge Regression), various activation functions, number of hidden layers and nodes and activation functions.  \n",
    "\n",
    "As stated in the introduction, it can also be useful to study other\n",
    "datasets. \n",
    "\n",
    "Again, we strongly recommend that you compare your own neural Network\n",
    "code for classification and pertinent results against a similar code using **Scikit-Learn**  or **tensorflow/keras** or **pytorch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLAN:\n",
    "1. last ned breast cancer data set\n",
    "2. bruk ffnn til klassifikasjon (med ... som siste lag)\n",
    "3. Bruk back propogation for å forbedre svaret\n",
    "4. bruke accuracy til å teste resultatene mine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, cost: 7.425800135116566\n",
      "Epoch 100, cost: 0.4707271892023921\n",
      "Epoch 200, cost: 0.4092915418634345\n",
      "Epoch 300, cost: 0.36438613483160087\n",
      "Epoch 400, cost: 0.3059849632746287\n",
      "Epoch 500, cost: 0.22964223520345023\n",
      "Epoch 600, cost: 0.16409843141785738\n",
      "Epoch 700, cost: 0.10720649327521015\n",
      "Epoch 800, cost: 0.0830317814696313\n",
      "Epoch 900, cost: 0.07734931057410602\n",
      "Accuracy on test set: 0.965034965034965\n",
      "False positives:  1\n",
      "True positives:  85\n",
      "False Negatives:  4\n",
      "True negatives:  53\n"
     ]
    }
   ],
   "source": [
    "## https://gpt.uio.no/chat/810796\n",
    "import autograd.numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import FFNN as fn\n",
    "import random\n",
    "\n",
    "np.random.seed(42) #random seed to ensure reproducibility\n",
    "# Load and preprocess the Wisconsin Breast Cancer dataset\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42) \n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "output_layer = [1]\n",
    "hidden_layers = [10]  \n",
    "layers = fn.create_layers_batch(input_size, hidden_layers+output_layer)\n",
    "activation_funcs = [fn.ReLU, fn.ReLU]\n",
    "activation_ders = [fn.ReLU_der, fn.ReLU_der]\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    grads =fn.backpropagation_batch(X_train, layers, activation_funcs, y_train, activation_ders)\n",
    "    for i, (W, b) in enumerate(layers):\n",
    "        dW, db = grads[i]\n",
    "        W -= learning_rate * dW\n",
    "        b -= learning_rate * db\n",
    "        layers[i] = (W, b)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        cost_value = fn.cost_batch(layers, X_train, activation_funcs, y_train)\n",
    "        print(f\"Epoch {epoch}, cost: {cost_value}\")\n",
    "\n",
    "# Evaluate the model\n",
    "prediction = fn.feed_forward_batch(X_test, layers, activation_funcs)\n",
    "prediction = np.round(prediction) \n",
    "accuracy = accuracy_score(y_test, prediction) ## prediction is 1 or 0\n",
    "print(f\"Accuracy on test set: {accuracy}\")\n",
    "\n",
    "##confusion matrix:\n",
    "falseP = 0\n",
    "trueP = 0\n",
    "falseN = 0\n",
    "trueN = 0\n",
    "\n",
    "for i in range(prediction.size):\n",
    "    pred = prediction[i][0]\n",
    "    sol = y_test[i][0]\n",
    "    if pred==1 and sol==0 :\n",
    "        falseP += 1\n",
    "    elif pred==1 and sol==1:\n",
    "        trueP +=1\n",
    "    elif pred==0 and sol==1:\n",
    "        falseN +=1\n",
    "    else:\n",
    "        trueN +=1\n",
    "\n",
    "print(\"False positives: \", falseP )\n",
    "print(\"True positives: \", trueP)\n",
    "print(\"False Negatives: \", falseN )\n",
    "print(\"True negatives: \", trueN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split har et parameter test_size, som er initialisert til å være 0.25. \n",
    "\n",
    "sigmpid, relu, sigmoid: lr=0.01, e=1000, test_size=0.99\n",
    "Accuracy on test set: 0.6294326241134752\n",
    "-||- test_size = 0.1\n",
    "Accuracy on test set: 0.8947368421052632\n",
    "\n",
    "relu, sigmoid, -||- test =0.1\n",
    "Accuracy on test set: 0.7017543859649122\n",
    "\n",
    "sigmoid, sigmoid -||-\n",
    "Accuracy on test set: 0.8771929824561403\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
