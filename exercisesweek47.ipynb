{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c0b63f",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- HTML file automatically generated from DocOnce source (https://github.com/doconce/doconce/)\n",
    "doconce format html exercisesweek47.do.txt  -->\n",
    "<!-- dom:TITLE: Exercise week 47 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb10d9d",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Exercise week 47\n",
    "**November 18-22, 2024**\n",
    "\n",
    "Date: **Deadline is Friday November 22 at midnight**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90add8",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Overarching aims of the exercises this week\n",
    "\n",
    "The exercise set this week is meant as a summary of many of the\n",
    "central elements in various machine learning algorithms, with a slight\n",
    "bias towards deep learning methods and their training. You don't need to answer all questions.\n",
    "\n",
    "The last weekly exercise (week 48) is a general course survey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f3ae78",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 1: Linear and logistic regression methods\n",
    "\n",
    "1. What is the main difference between ordinary least squares and Ridge regression?\n",
    "\n",
    "2. Which kind of data set would you use logistic regression for?\n",
    "\n",
    "3. In linear regression you assume that your output is described by a continuous non-stochastic function $f(x)$. Which is the equivalent function in logistic regression?\n",
    "\n",
    "4. Can you find an analytic solution to a logistic regression type of problem?\n",
    "\n",
    "5. What kind of cost function would you use in logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7136b",
   "metadata": {},
   "source": [
    "1. Ridge has a normalization parameter.\n",
    "\n",
    "2. Binary classification.\n",
    "\n",
    "3. Sigmoid.\n",
    "\n",
    "4. No.\n",
    "\n",
    "5. Binary cross-entropy loss function. Or log-likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755cfd27",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 2: Deep learning\n",
    "\n",
    "1. What is an activation function and discuss the use of an activation function? Explain three different types of activation functions?\n",
    "\n",
    "2. Describe the architecture of a typical feed forward  Neural Network (NN). \n",
    "\n",
    "3. You are using a deep neural network for a prediction task. After training your model, you notice that it is strongly overfitting the training set and that the performance on the test isnâ€™t good. What can you do to reduce overfitting?\n",
    "\n",
    "4. How would you know if your model is suffering from the problem of exploding Gradients?\n",
    "\n",
    "5. Can you name and explain a few hyperparameters used for training a neural network?\n",
    "\n",
    "6. Describe the architecture of a typical Convolutional Neural Network (CNN)\n",
    "\n",
    "7. What is the vanishing gradient problem in Neural Networks and how to fix it?\n",
    "\n",
    "8. When it comes to training an artificial neural network, what could the reason be for why the cost/loss doesn't decrease in a few epochs?\n",
    "\n",
    "9. How does L1/L2 regularization affect a neural network?\n",
    "\n",
    "10. What is(are) the advantage(s) of deep learning over traditional methods like linear regression or logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be85b8",
   "metadata": {},
   "source": [
    "1. An activation function evaluates the input values at each layer, and calculates the values for the next layer. It is used to prevent outliers in the data, like prevent negative values or zeros.\n",
    "Sigmoid - log reg, returns values between 0 and 1\n",
    "ReLU - returns values between 0 and infinity\n",
    "Leaky ReLU - allows small negative values, to prevent 0s (dead nodes)\n",
    "\n",
    "2. Input layer - Hidden layer(s) - Output layer\n",
    "They are all connected in one direction. From input to output. Can have multiple nodes. \n",
    "\n",
    "3. Reduce overfitting to training data by reducing batch size (number of iterations). Change learning rate. Reshuffling of data (training) for every epoch. \n",
    "\n",
    "4. By getting values outside of our range (e.g 2 in a binary classification case). Alternatively, not reaching a optimum (global minimum).\n",
    "\n",
    "5. Hyperparameters - parameter predefined by us. Parameter - learned from training.\n",
    "learning rate: how \"fast\" we move/large the steps are between iterations.\n",
    "number of epochs: number of times we run over the learning algorithm.\n",
    "number of hidden layers/nodes: how many times we evaluate the input before the ouput. And how often in each layer.\n",
    "\n",
    "6. CNN is explicitely used for images. Uses discrete convolution, e.g. reduces parameters inside the layers for our linear transformation. \n",
    "\n",
    "7. Gradients diminish as they are propagated backwards, and then the weights will not be updated as they should (get stuck almost). Can be fixed by doing the right weight initialization, depending on the activation functions used.\n",
    "\n",
    "8. Stuck in a local minimum.\n",
    "\n",
    "9. Regularization using L1 (LASSO) will add a penalty to remove certain unimportant features (drive them to zero). Feature selection\n",
    "L2 (Ridge) will also reduce certain parameters, but not drive them to zero. Can prevent overfitting (like L1).\n",
    "\n",
    "10. Deep learning can solve more complex problems, and is useful when you don't have an analytical expression. \n",
    "Large language models - cannot be used for lin reg :p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85175b87",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 3: Decision trees and ensemble methods\n",
    "\n",
    "1. Mention some pros and cons when using decision trees\n",
    "\n",
    "2. How do we grow a tree? And which are the main parameters? \n",
    "\n",
    "3. Mention some of the benefits with using ensemble methods (like bagging, random forests and boosting methods)?\n",
    "\n",
    "4. Why would you prefer a random forest instead of using Bagging to grow a forest?\n",
    "\n",
    "5. What is the basic philosophy behind boosting methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572e034",
   "metadata": {},
   "source": [
    "1. \n",
    "Pros: Relatively easy to implement.\n",
    "Cons: Prone to overfitting, can be unecessarily large and complex. \n",
    "\n",
    "\n",
    "2. \n",
    "A tree consists of root nodes, interior nodes, and leaf nodes. The root nodes are the input nodes and the leaf nodes are output nodes. The main idea is to find the most descriptive features and then split the dataset along their values to keep the features as pure as possible. \n",
    "\n",
    "We grow a tree like this: (From Lecture notes).\n",
    "\n",
    "        1. Find a dataset in which the data is described by several characteristic features and a target feature. \n",
    "\n",
    "        2. Train the model by splitting the target feature along the characteristic features using information gained during the training process.\n",
    "\n",
    "        3. Grow the tree until we accomplish a stopping criterion. Create predictions in the form of leaf nodes.\n",
    "\n",
    "        4. Use the tree to make predictions, by running test data through each branch. \n",
    "\n",
    "The main parameters are the depth of the tree, \n",
    "\n",
    "3. \n",
    "Ensamble methods are good for reducing the variance of the model, i.e. reducing the chance of overfitting the model. It can also lead to higher accuracy than using a single decision tree. We can use the gini index \n",
    "\n",
    "\n",
    "4. \n",
    "Random forest creates trees using random features, ensuring a more diverse forest. Bagging used the same features, which makes the model more likely to overfit. \n",
    "\n",
    "\n",
    "5. \n",
    "Boosting methods ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfdfe68",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 4: Optimization part\n",
    "\n",
    "1. Which is the basic mathematical root-finding method behind essentially all gradient descent approaches(stochastic and non-stochastic)? \n",
    "\n",
    "2. And why don't we use it? Or stated differently, why do we introduce the learning rate as a parameter?\n",
    "\n",
    "3. What might happen if you set the momentum hyperparameter too close to 1 (e.g., 0.9999) when using an optimizer for the learning rate?\n",
    "\n",
    "4. Why should we use stochastic gradient descent instead of plain gradient descent?\n",
    "\n",
    "5. Which parameters would you need to tune when use a stochastic gradient descent approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fc1b0c",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Exercise 5: Analysis of results\n",
    "1. How do you assess overfitting and underfitting?\n",
    "\n",
    "2. Why do we divide the data in test and train and/or eventually validation sets?\n",
    "\n",
    "3. Why would you use resampling methods in the data analysis? Mention some widely popular resampling methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26f3da",
   "metadata": {},
   "source": [
    "1. There are multiple ways to asses over- or underfitting. We can look at the MSE, R2, Accuracy or the Confusion Matrix for example.\n",
    "\n",
    "2. To properly train and followingly assess our model. Training on the wole dataset woeuld likely lead to overfitting and would leave us with no data that we can test our model and the trained parameters on. \n",
    "\n",
    "3. To also be able to work with a limited data set. Resampling methods would be for example Bootstrap or Cross -validation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
